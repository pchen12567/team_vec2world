{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:36:43.310073Z",
     "start_time": "2019-05-11T04:36:41.629356Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:37:25.396254Z",
     "start_time": "2019-05-11T04:37:25.390551Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '../corpus/data/total_news_corpus.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:37:41.268674Z",
     "start_time": "2019-05-11T04:37:38.842994Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:38:40.182176Z",
     "start_time": "2019-05-11T04:38:40.169095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total News Number: 98498\n"
     ]
    }
   ],
   "source": [
    "# Check news total number\n",
    "print('Total News Number: {}'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:49:20.591935Z",
     "start_time": "2019-05-11T04:49:20.569556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34852</th>\n",
       "      <td>25966</td>\n",
       "      <td>多特蒙德爆炸|因为足球，他们站在一起</td>\n",
       "      <td>\\n新华社巴黎4月12日新媒体专电　题：因为足球，他们站在一起\\n新华社记者苏斌\\n因为足球...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97741</th>\n",
       "      <td>88855</td>\n",
       "      <td>（社会）（1）北京S1线跨永定河大桥钢梁即将顶推就位</td>\n",
       "      <td>新华社照片，北京，2017年6月6日\\n北京S1线跨永定河大桥钢梁即将顶推就位\\n北京S1线...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33410</th>\n",
       "      <td>24524</td>\n",
       "      <td>（体育）（1）游泳——冠军赛：傅园慧晋级100米仰泳决赛</td>\n",
       "      <td>新华社照片，青岛（山东），2017年4月11日\\n（体育）（1）游泳——冠军赛：傅园慧晋级1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19460</th>\n",
       "      <td>9129</td>\n",
       "      <td>台\"立法院\"临时会无同婚议题 挺同团体盼秋季前通过</td>\n",
       "      <td>华夏经纬网6月13日讯：据台湾媒体报道，台“立法院”下周将召开临时会，但并未排审同婚“法案”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18466</th>\n",
       "      <td>7095</td>\n",
       "      <td>看升旗：黑大毕业生的最后一堂爱国主义教育课</td>\n",
       "      <td>央广网哈尔滨6月22日消息（记者迟嵩 通讯员勾慧明 牛春莳）6月22日，黑龙江大学在联通广场...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                         title  \\\n",
       "34852  25966            多特蒙德爆炸|因为足球，他们站在一起   \n",
       "97741  88855    （社会）（1）北京S1线跨永定河大桥钢梁即将顶推就位   \n",
       "33410  24524  （体育）（1）游泳——冠军赛：傅园慧晋级100米仰泳决赛   \n",
       "19460   9129     台\"立法院\"临时会无同婚议题 挺同团体盼秋季前通过   \n",
       "18466   7095         看升旗：黑大毕业生的最后一堂爱国主义教育课   \n",
       "\n",
       "                                                 content  \n",
       "34852  \\n新华社巴黎4月12日新媒体专电　题：因为足球，他们站在一起\\n新华社记者苏斌\\n因为足球...  \n",
       "97741  新华社照片，北京，2017年6月6日\\n北京S1线跨永定河大桥钢梁即将顶推就位\\n北京S1线...  \n",
       "33410  新华社照片，青岛（山东），2017年4月11日\\n（体育）（1）游泳——冠军赛：傅园慧晋级1...  \n",
       "19460  华夏经纬网6月13日讯：据台湾媒体报道，台“立法院”下周将召开临时会，但并未排审同婚“法案”...  \n",
       "18466  央广网哈尔滨6月22日消息（记者迟嵩 通讯员勾慧明 牛春莳）6月22日，黑龙江大学在联通广场...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:50:56.427892Z",
     "start_time": "2019-05-11T04:50:56.219725Z"
    }
   },
   "outputs": [],
   "source": [
    "news = df['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:51:33.417693Z",
     "start_time": "2019-05-11T04:51:33.413818Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:51:34.471738Z",
     "start_time": "2019-05-11T04:51:34.467814Z"
    }
   },
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    return re.findall(r'[\\d|\\w]+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:52:18.624649Z",
     "start_time": "2019-05-11T04:52:14.568016Z"
    }
   },
   "outputs": [],
   "source": [
    "news = [token(str(n)) for n in news]\n",
    "news = [''.join(n) for n in news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:52:39.152387Z",
     "start_time": "2019-05-11T04:52:39.144640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现如今随着各大赛区2019年新赛季的接近各位职业选手为了尽快调整好自己的状态也是纷纷开始了自己的冲分之旅比如像SN的新打野选手就冲到了韩服第二名而像rookiejackeylove等上分如喝水选手也是重回韩服高分段可是就在这种大背景下一名职业选手最近却是遨游黑铁段位甚至还遭到了队友的无情嘲讽这到底是怎么一回事呢事情的主人公还是我们的锅老师由于新赛季段位重置的缘故mlxg在国服的账号经过了九胜一负的排位赛之后竟然只定位到了黑铁四其实作为一名职业选手来说mlxg原本在韩服的排位分数并不出众钻石打野王的称号也不是空穴来风但是谁曾想到mlxg竟然还有沦落到黑铁段位的时候不过mlxg对于自己这个段位还是非常看得开的在每局游戏开始的时候还会非常调皮的发一些能够让所有人都看到的骚话比如什么大家好请叫我黑铁打野王不过很明显并不是所有的队友都会给mlxg好脸色比如下面的这名玩家在某局游戏的开始mlxg再次非常调皮的发送了一句各位大哥大姐求求你们带我上个青铜吧可是这时一名队友却突然毫不客气的回复道爷不想带你确实由于mlxg隐藏分太高的缘故这几天匹配到的队友都是钻石的大神对于一名钻石段位的玩家来说去带一名黑铁的萌新的确是一件既丢份又浪费时间的事情不过虽然被队友怼了但是mlxg的做法却是非常的正确既然你不想带我那么就让我来带你吧最终在mlxg的carry下这名回怼mlxg的玩家也是几乎以躺赢的姿态结束了这局游戏可能这名玩家现在也正在为自己与一位真正大神发生矛盾而后悔不已吧而经过自己的努力mlxg在这两天也是终于晋级青铜分段看来黑铁打野王的称号已经不适用了啊各位同学你们觉得青铜段位的锅老师应该叫什么样的外号呢'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:52:57.183673Z",
     "start_time": "2019-05-11T04:52:57.122822Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:53:04.614907Z",
     "start_time": "2019-05-11T04:53:04.609856Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut(string):\n",
    "    return ' '.join(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:57:22.561173Z",
     "start_time": "2019-05-11T04:53:41.458764Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/jc/l9vx9tp979g0tm976wjrgwkr0000gn/T/jieba.cache\n",
      "Loading model cost 0.870 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "news = [cut(n) for n in news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T04:58:10.526387Z",
     "start_time": "2019-05-11T04:58:10.517091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现如今 随着 各大 赛区 2019 年 新 赛季 的 接近 各位 职业 选手 为了 尽快 调整 好 自己 的 状态 也 是 纷纷 开始 了 自己 的 冲分 之 旅 比如 像 SN 的 新 打野 选手 就 冲到 了 韩服 第二名 而 像 rookiejackeylove 等 上 分如 喝水 选手 也 是 重回 韩服 高分 段 可是 就 在 这种 大 背景 下 一名 职业 选手 最近 却是 遨游 黑铁 段位 甚至 还 遭到 了 队友 的 无情 嘲讽 这 到底 是 怎么 一 回事 呢 事情 的 主人公 还是 我们 的 锅 老师 由于 新 赛季 段位 重置 的 缘故 mlxg 在 国服 的 账号 经过 了 九胜 一负 的 排位赛 之后 竟然 只 定位 到 了 黑铁 四 其实 作为 一名 职业 选手 来说 mlxg 原本 在 韩服 的 排位 分数 并 不 出众 钻石 打 野王 的 称号 也 不是 空穴来风 但是 谁 曾 想到 mlxg 竟然 还有 沦落 到 黑铁 段位 的 时候 不过 mlxg 对于 自己 这个 段位 还是 非常 看得开 的 在 每局 游戏 开始 的 时候 还会 非常 调皮 的 发 一些 能够 让 所有人 都 看到 的 骚话 比如 什么 大家 好 请 叫 我 黑铁 打 野王 不过 很 明显 并 不是 所有 的 队友 都 会 给 mlxg 好 脸色 比如 下面 的 这名 玩家 在 某局 游戏 的 开始 mlxg 再次 非常 调皮 的 发送 了 一句 各位 大哥 大姐 求求 你们 带 我 上 个 青铜 吧 可是 这时 一名 队友 却 突然 毫不客气 的 回复 道 爷 不想 带 你 确实 由于 mlxg 隐藏 分太高 的 缘故 这 几天 匹配 到 的 队友 都 是 钻石 的 大神 对于 一名 钻石 段位 的 玩家 来说 去 带 一名 黑铁 的 萌新 的确 是 一件 既 丢份 又 浪费时间 的 事情 不过 虽然 被 队友 怼 了 但是 mlxg 的 做法 却是 非常 的 正确 既然 你 不想 带 我 那么 就让 我来 带 你 吧 最终 在 mlxg 的 carry 下 这名 回 怼 mlxg 的 玩家 也 是 几乎 以 躺 赢 的 姿态 结束 了 这局 游戏 可能 这名 玩家 现在 也 正在 为 自己 与 一位 真正 大神 发生 矛盾 而 后悔不已 吧 而 经过 自己 的 努力 mlxg 在 这 两天 也 是 终于 晋级 青铜 分段 看来 黑铁 打 野王 的 称号 已经 不 适用 了 啊 各位 同学 你们 觉得 青铜 段位 的 锅 老师 应该 叫 什么样 的 外号 呢'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:00:31.328234Z",
     "start_time": "2019-05-11T05:00:30.246392Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../corpus/data/total_news_sentences_cut.txt', 'w') as f:\n",
    "    for n in news:\n",
    "        f.write(n + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T01:16:50.399876Z",
     "start_time": "2019-05-12T01:16:50.392062Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T00:55:33.249914Z",
     "start_time": "2019-05-12T00:53:02.968434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 37s, sys: 4.62 s, total: 6min 41s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "news_word2vec = Word2Vec(LineSentence('../corpus/data/total_news_sentences_cut.txt'),\n",
    "                            sg=0, min_count=10, size=100, window=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T01:20:32.332714Z",
     "start_time": "2019-05-12T01:20:32.323500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('表示', 0.8120302557945251),\n",
       " ('指出', 0.7441439032554626),\n",
       " ('认为', 0.7348392009735107),\n",
       " ('说完', 0.7054398059844971),\n",
       " ('告诉', 0.6980290412902832),\n",
       " ('坦言', 0.689932644367218),\n",
       " ('看来', 0.6718833446502686),\n",
       " ('明说', 0.6416362524032593),\n",
       " ('称', 0.6323878765106201),\n",
       " ('介绍', 0.6100223064422607),\n",
       " ('强调', 0.5975658893585205),\n",
       " ('地说', 0.5793262720108032),\n",
       " ('透露', 0.5747420787811279),\n",
       " ('文说', 0.5690529942512512),\n",
       " ('所说', 0.5660392045974731),\n",
       " ('中说', 0.5455971360206604),\n",
       " ('问', 0.541256308555603),\n",
       " ('说道', 0.5322377681732178),\n",
       " ('承认', 0.5153343081474304),\n",
       " ('时说', 0.5070992708206177)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_word2vec.most_similar('说', topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T01:11:10.968251Z",
     "start_time": "2019-05-12T01:11:03.920730Z"
    }
   },
   "outputs": [],
   "source": [
    "news_word2vec.wv.save_word2vec_format('./news_word2vec_mode.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:24:29.220370Z",
     "start_time": "2019-05-12T02:24:25.653574Z"
    }
   },
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:24:37.342869Z",
     "start_time": "2019-05-12T02:24:30.099100Z"
    }
   },
   "outputs": [],
   "source": [
    "# news_word2vec = KeyedVectors.load_word2vec_format('./news_word2vec_mode.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:24:38.644398Z",
     "start_time": "2019-05-12T02:24:38.638203Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:41:39.003455Z",
     "start_time": "2019-05-11T06:41:38.937150Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_related_words(init_words, model, max_size, top_n):\n",
    "    \"\"\"\n",
    "    @ init_words: initial words we already know\n",
    "    @ model: the word2vec model\n",
    "    @ max_size: the maximum number of words need to see\n",
    "    @ top_n: the number of top similar words\n",
    "    \"\"\"\n",
    "    \n",
    "    # Init unseen words list\n",
    "    unseen_list = init_words\n",
    "    \n",
    "    # Init seen words dict\n",
    "    seen = defaultdict(int)\n",
    "    \n",
    "    # Init sub nodes dict\n",
    "    sub_nodes_dic = defaultdict(list)\n",
    "    \n",
    "    # Scan unseen words list if length of seen words dict less than max_size\n",
    "    while unseen_list and len(seen) < max_size:\n",
    "        \n",
    "        # Get first word in unseen words list\n",
    "        node = unseen_list.pop(0)\n",
    "        \n",
    "        # Get sub nodes directly if in dict\n",
    "        if node in sub_nodes_dic:\n",
    "            sub_nodes = sub_nodes_dic[node]\n",
    "        \n",
    "        else:\n",
    "            # Get top_n similar words for first word by word2vec model\n",
    "            sub_nodes = [w for w, s in model.wv.most_similar(node, topn=top_n)]\n",
    "            \n",
    "            # Save result to sub nodes dict\n",
    "            sub_nodes_dic[node] = sub_nodes\n",
    "        \n",
    "        # Add similar words result to unseen words list\n",
    "        unseen_list += sub_nodes\n",
    "        \n",
    "        # Save current seen word and increase 1 weight\n",
    "        seen[node] += 1 # could be weighted by others\n",
    "        \n",
    "        # optimal: 1. score function could be revised\n",
    "    \n",
    "    # Sort seen words dict by words weight\n",
    "    seen_rank = sorted(seen.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return sorted list\n",
    "    return seen_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T00:57:25.372413Z",
     "start_time": "2019-05-12T00:56:10.950723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 1.84 s, total: 1min 59s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Set max_size = 10000 and top_n=50\n",
    "related_words = get_related_words(['说', '表示'], news_word2vec, max_size=10000, top_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T00:57:41.131569Z",
     "start_time": "2019-05-12T00:57:41.124599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('说道', 363), ('坦言', 330), ('表示', 258), ('称', 256), ('声称', 252), ('指出', 246), ('承认', 246), ('说', 245), ('直言', 240), ('认为', 235), ('说出', 231), ('说完', 219), ('看来', 213), ('告诉', 212), ('提到', 206), ('透露', 203), ('问', 201), ('写道', 199), ('感叹', 197), ('提及', 196), ('感慨', 195), ('所说', 184), ('强调', 180), ('批评', 179), ('否认', 172), ('地说', 169), ('如是说', 169), ('表态', 168), ('明说', 166), ('佩服', 166), ('却说', 165), ('暗示', 164), ('指责', 156), ('反驳', 156), ('问过', 154), ('猜测', 153), ('聊起', 152), ('介绍', 149), ('抨击', 147), ('澄清', 146), ('敦促', 138), ('中称', 127), ('质疑', 127), ('夸赞', 122), ('出面', 121), ('推测', 120), ('文说', 117), ('时说', 117), ('中说', 116), ('普遍认为', 116), ('翻看', 116), ('还称', 112), ('谈论', 112), ('回忆起', 112), ('知晓', 110), ('称赞', 107), ('重申', 107), ('回答', 107), ('坦承', 106), ('强调指出', 104), ('解释', 101), ('谈到', 100), ('建议', 99), ('疑惑', 99), ('对不起', 99), ('提议', 97), ('引用', 97), ('质问', 96), ('怀疑', 95), ('谈起', 95), ('纷纷表示', 95), ('呼吁', 94), ('回击', 94), ('忍不住', 93), ('言论', 93), ('纳说', 90), ('反问', 90), ('证实', 89), ('坚称', 89), ('宣称', 88), ('嘱咐', 88), ('调侃', 88), ('指认', 88), ('相信', 86), ('谴责', 86), ('听说', 85), ('抱怨', 85), ('说起', 84), ('发问', 83), ('描述', 83), ('提出', 81), ('觉得', 81), ('喊道', 81), ('说好', 81), ('否定', 80), ('劝', 79), ('干涉', 79), ('盛赞', 76), ('指控', 76), ('心疼', 75), ('说法', 74), ('眼中', 73), ('提醒', 72), ('羡慕', 71), ('别有用心', 70), ('庆幸', 70), ('财政司', 69), ('看法', 69), ('疑虑', 68), ('留意到', 68), ('观点', 67), ('地问', 67), ('眼里', 67), ('因斯', 66), ('阐述', 66), ('打趣', 66), ('深知', 65), ('列举', 65), ('问起', 64), ('报复', 64), ('激动', 63), ('问问', 63), ('大喊', 63), ('问道', 62), ('常务', 61), ('反思', 61), ('主张', 61), ('喊话', 61), ('分析', 60), ('询问', 60), ('夸奖', 59), ('干嘛', 59), ('担心', 58), ('一席话', 58), ('伤心', 58), ('给出', 57), ('内疚', 57), ('生气', 57), ('闭上眼睛', 56), ('提问', 56), ('援引', 56), ('行径', 56), ('痛批', 56), ('明白', 55), ('反对', 55), ('嘲讽', 55), ('假装', 55), ('置评', 55), ('直呼', 54), ('并称', 53), ('欣喜', 53), ('所言', 53), ('后悔', 53), ('道歉', 53), ('拒绝', 52), ('转述', 51), ('不怪', 51), ('恩师', 51), ('讨厌', 51), ('骂', 51), ('看出', 50), ('预料', 50), ('立场', 50), ('聊聊', 50), ('不说', 50), ('看得出来', 49), ('明确指出', 49), ('自称为', 49), ('深有体会', 49), ('力挺', 49), ('赞叹', 48), ('原话', 48), ('原谅', 48), ('解读', 47), ('告诫', 47), ('叮嘱', 47), ('感激', 47), ('举动', 47), ('引述', 46), ('一本正经', 46), ('时称', 46), ('追问', 46), ('听到', 46), ('好奇', 46), ('怒斥', 46), ('回应', 46), ('特别强调', 45), ('显然', 45), ('心里', 45), ('刊登', 45), ('为难', 45), ('据称', 44), ('聊到', 44), ('克说', 43), ('一笑', 43), ('一篇', 43), ('认出', 43), ('抹黑', 43), ('谈及', 42), ('知情', 42)]\n"
     ]
    }
   ],
   "source": [
    "related_top_200 = related_words[: 200]\n",
    "print(related_top_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimiz with Similarity Weight**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:27:26.492443Z",
     "start_time": "2019-05-12T02:27:26.476495Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_related_words(init_words, model, max_size, top_n):\n",
    "    \"\"\"\n",
    "    @ init_words: initial words we already know\n",
    "    @ model: the word2vec model\n",
    "    @ max_size: the maximum number of words need to see\n",
    "    @ top_n: the number of top similar words\n",
    "    \"\"\"\n",
    "    \n",
    "    # Init unseen words list\n",
    "    unseen_list = init_words\n",
    "    \n",
    "    # Init seen words dict\n",
    "    seen = defaultdict(int)\n",
    "    \n",
    "    # Init sub nodes dict\n",
    "    sub_nodes_dic = defaultdict(list)\n",
    "    \n",
    "    # Scan unseen words list if length of seen words dict less than max_size\n",
    "    while unseen_list and len(seen) < max_size:\n",
    "        \n",
    "        # Get first word in unseen words list\n",
    "        node = unseen_list.pop(0)\n",
    "        \n",
    "        # Get sub nodes directly if in dict\n",
    "        if node in sub_nodes_dic:\n",
    "            sub_nodes = sub_nodes_dic[node]\n",
    "        \n",
    "        else:\n",
    "            # Get top_n similar words for first word by word2vec model\n",
    "            sub_nodes = [w for w, s in model.most_similar(node, topn=top_n)]\n",
    "            \n",
    "            # Save result to sub nodes dict\n",
    "            sub_nodes_dic[node] = sub_nodes\n",
    "        \n",
    "        # Add similar words result to unseen words list\n",
    "        unseen_list += sub_nodes\n",
    "        \n",
    "        # Save current seen word and increase 1 weight\n",
    "        seen[node] += 1 # could be weighted by others\n",
    "        \n",
    "        # optimal: 1. score function could be revised\n",
    "    \n",
    "    for word, value in seen.items():        \n",
    "        \n",
    "            weight = model.similarity(init_words[0], word)\n",
    "\n",
    "            seen[word] = value * weight\n",
    "       \n",
    "    \n",
    "    # Sort seen words dict by words weight\n",
    "    seen_rank = sorted(seen.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return sorted list\n",
    "    return [w for w, s in seen_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:28:40.120473Z",
     "start_time": "2019-05-12T02:27:31.930771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 8s, sys: 714 ms, total: 2min 8s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Set max_size = 10000 and top_n=50\n",
    "related_words = get_related_words(['说', '表示'], news_word2vec, max_size=10000, top_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:28:46.003290Z",
     "start_time": "2019-05-12T02:28:45.990510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['说道', '直言', '佩服', '却说', '说出', '感慨', '看来', '感叹', '地说', '所说', '对不起', '认为', '说完', '问', '反驳', '心疼', '夸赞', '疑惑', '羡慕', '说', '觉得', '问过', '告诉', '怀疑', '坦言', '说好', '聊起', '抱怨', '眼里', '反问', '承认', '讨厌', '回答', '喊道', '眼中', '伤心', '调侃', '质疑', '推测', '劝', '明说', '夸奖', '忍不住', '解释', '纷纷表示', '庆幸', '嘱咐', '猜测', '问问', '生气', '称赞', '翻看', '批评', '坦承', '干嘛', '骂', '打趣', '质问', '直呼', '谈论', '不说', '激动', '地问', '说起', '看得出来', '一席话', '为难', '假装', '内疚', '嘲讽', '原谅', '深知', '好奇', '否定', '强调指出', '闭上眼睛', '委屈', '看不起', '担心', '腼腆', '一笑', '后悔', '问起', '认出', '知晓', '敬佩', '描述', '写道', '谈起', '一脸', 'jpg', '问道', '心里', '欣喜', '大喊', '其实', '建议', '相信', '回击', '在乎', '指责', '一本正经', '回忆起', '感激', '明白', '想想', '赞叹', '更何况', '留意到', '摇头', '郁闷', '脱口而出', '如是说', '谦虚', '欣慰', '心酸', '坚称', '难受', '羞涩', '显然', '嘛', '害怕', '记住', '妈', '心痛', '毕竟', '惊讶', '听说', '言论', '说真的', '说实话', '难过', '强调', '嗯', '满脸', '不怪', '不信', '发问', '常说', '意料', '确信', '想必', '看法', '呛', '责怪', '沮丧', '形容', '提到', '开玩笑', '告诫', '惋惜', '提醒', '说不出', '自豪', '所言', '别有用心', '深有体会', '观点', '嘲笑', '想不到', '聊到', '以为', '赞美', '钦佩', '胡说八道', '恩师', '说法', '原话', '聊聊', '为啥', '普遍认为', '安慰', '理解', '预料', '看见', '吃惊', '撕心裂肺', '没错', '得意', '看得出', '苦恼', '声称', '干什么', '大赞', '反正', '欺负', '吐槽', '挑剔', '的确', '在我看来', '反思', '的话', '聪明', '痛批', '林说', '想起', '诧异', '不屑', '爱看', '考虑一下']\n"
     ]
    }
   ],
   "source": [
    "related_top_200 = related_words[: 200]\n",
    "print(related_top_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimiz Result with Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:33:38.242818Z",
     "start_time": "2019-05-12T02:33:38.239110Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words_path = './chinese_stop_words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:34:56.866462Z",
     "start_time": "2019-05-12T02:34:56.842785Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_list = []\n",
    "\n",
    "with open(stop_words_path, 'r') as f:\n",
    "    for line in f:\n",
    "        stop_list.append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:36:43.640935Z",
     "start_time": "2019-05-12T02:36:43.228287Z"
    }
   },
   "outputs": [],
   "source": [
    "words_list = []\n",
    "\n",
    "for w in related_words:\n",
    "    if w not in stop_list:\n",
    "        words_list.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T02:36:57.872673Z",
     "start_time": "2019-05-12T02:36:57.868416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['说道', '直言', '佩服', '却说', '说出', '感慨', '看来', '感叹', '地说', '所说', '对不起', '认为', '说完', '反驳', '心疼', '夸赞', '疑惑', '羡慕', '觉得', '问过', '告诉', '怀疑', '坦言', '说好', '聊起', '抱怨', '眼里', '反问', '承认', '讨厌', '回答', '喊道', '眼中', '伤心', '调侃', '质疑', '推测', '劝', '明说', '夸奖', '忍不住', '解释', '纷纷表示', '庆幸', '嘱咐', '猜测', '问问', '生气', '称赞', '翻看', '批评', '坦承', '干嘛', '骂', '打趣', '质问', '直呼', '谈论', '不说', '激动', '地问', '说起', '看得出来', '一席话', '为难', '假装', '内疚', '嘲讽', '原谅', '深知', '好奇', '否定', '强调指出', '闭上眼睛', '委屈', '看不起', '担心', '腼腆', '一笑', '后悔', '问起', '认出', '知晓', '敬佩', '描述', '写道', '谈起', '一脸', 'jpg', '问道', '心里', '欣喜', '大喊', '其实', '建议', '相信', '回击', '在乎', '指责', '一本正经', '回忆起', '感激', '明白', '想想', '赞叹', '更何况', '留意到', '摇头', '郁闷', '脱口而出', '如是说', '谦虚', '欣慰', '心酸', '坚称', '难受', '羞涩', '显然', '害怕', '记住', '妈', '心痛', '毕竟', '惊讶', '听说', '言论', '说真的', '说实话', '难过', '强调', '满脸', '不怪', '不信', '发问', '常说', '意料', '确信', '想必', '看法', '呛', '责怪', '沮丧', '形容', '提到', '开玩笑', '告诫', '惋惜', '提醒', '说不出', '自豪', '所言', '别有用心', '深有体会', '观点', '嘲笑', '想不到', '聊到', '以为', '赞美', '钦佩', '胡说八道', '恩师', '说法', '原话', '聊聊', '为啥', '普遍认为', '安慰', '理解', '预料', '看见', '吃惊', '撕心裂肺', '没错', '得意', '看得出', '苦恼', '声称', '干什么', '大赞', '反正', '欺负', '吐槽', '挑剔', '的确', '在我看来', '反思', '的话', '聪明', '痛批', '林说', '想起', '诧异', '不屑', '爱看', '考虑一下', '我怕', '哈哈大笑', '调皮', '讲讲']\n"
     ]
    }
   ],
   "source": [
    "related_top_200 = words_list[: 200]\n",
    "print(related_top_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
